import pandas as pd
from datetime import datetime
import os
import requests
import jwt
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.backends import default_backend
import time
from dotenv import load_dotenv
from tqdm import tqdm
import json

# --- 1. Configura√ß√£o e Constantes ---
load_dotenv()
SF_LOGIN_URL = os.getenv("SF_LOGIN_URL", "https://login.salesforce.com")
SF_CLIENT_ID = os.getenv("SF_CLIENT_ID")
SF_USERNAME = os.getenv("SF_USERNAME")
SF_PRIVATE_KEY_FILE = os.getenv("SF_PRIVATE_KEY_FILE", "private.pem")
USE_PROXY = os.getenv("USE_PROXY", "True").lower() == "true"
PROXY_URL = os.getenv("PROXY_URL")
VERIFY_SSL = os.getenv("VERIFY_SSL", "False").lower() == "true"
proxies = {'http': PROXY_URL, 'https': PROXY_URL} if USE_PROXY else None

# --- Constantes Espec√≠ficas da Tarefa ---
API_VERSION = "v64.0"
INPUT_CSV_FILE = "dmo_list.csv"
NEW_DATA_SPACE_NAME = 'IUBR'
NEW_DMO_PREFIX = "iub_"
SYSTEM_FIELDS_TO_EXCLUDE = ("DataSourceObject__c", "DataSource__c", "InternalOrganization__c")
REQUESTS_TIMEOUT = 90 

# --- Modos de Opera√ß√£o ---
RUN_CLONE_DMO = os.getenv("RUN_CLONE_DMO", "True").lower() == "true"
RUN_CREATE_MAPPING = os.getenv("RUN_CREATE_MAPPING", "True").lower() == "true"

def get_timestamp():
    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

# --- Fun√ß√µes de API ---
def authenticate_jwt(login_url, client_id, username, private_key_file):
    print(f"{get_timestamp()} üîê  Iniciando autentica√ß√£o JWT...")
    try:
        with open(private_key_file, "rb") as key_file:
            private_key = serialization.load_pem_private_key(key_file.read(), password=None, backend=default_backend())
        payload = {"iss": client_id, "sub": username, "aud": login_url, "exp": int(time.time()) + 180}
        token = jwt.encode(payload, private_key, algorithm="RS256")
        data = {"grant_type": "urn:ietf:params:oauth:grant-type:jwt-bearer", "assertion": token}
        auth_url = f"{login_url}/services/oauth2/token"
        response = requests.post(auth_url, data=data, proxies=proxies, verify=VERIFY_SSL, timeout=REQUESTS_TIMEOUT)
        response.raise_for_status()
        auth_data = response.json()
        print(f"{get_timestamp()} ‚úÖ  Autentica√ß√£o bem-sucedida!")
        return auth_data.get('access_token'), auth_data.get('instance_url')
    except Exception as e:
        print(f"{get_timestamp()} ‚ùå ERRO DE AUTENTICA√á√ÉO: {e}")
        return None, None

def get_dmo_definition(access_token, instance_url, dmo_name):
    get_url = f"{instance_url}/services/data/{API_VERSION}/ssot/data-model-objects/{dmo_name}"
    headers = {"Authorization": f"Bearer {access_token}"}
    try:
        response = requests.get(get_url, headers=headers, proxies=proxies, verify=VERIFY_SSL, timeout=REQUESTS_TIMEOUT)
        response.raise_for_status()
        print(f"{get_timestamp()}    - GET DMO bem-sucedido para {dmo_name}")
        return response.json()
    except requests.exceptions.HTTPError as e:
        print(f"{get_timestamp()}    - ‚ùå ERRO no GET DMO para {dmo_name}: {e.response.status_code} - {e.response.text}")
        return None

def create_new_dmo(access_token, instance_url, get_payload):
    if not get_payload: return None, False
    original_label = get_payload.get('label', '')
    original_api_name = get_payload.get('name', '')
    base_api_name = original_api_name.replace('__dlm', '')
    post_payload = {"name": f"{NEW_DMO_PREFIX}{base_api_name}", "label": original_label, "description": get_payload.get('description', ''), "dataSpaceName": NEW_DATA_SPACE_NAME, "category": get_payload.get('category', 'OTHER'), "fields": []}
    for field in get_payload.get('fields', []):
        if field.get('creationType') == 'System': continue
        post_payload["fields"].append({"name": field.get('name', '').replace('__c', ''), "label": field.get('label', ''), "description": field.get('description', ''), "isPrimaryKey": field.get('isPrimaryKey', False), "isDynamicLookup": False, "dataType": field.get('type')})
    post_url = f"{instance_url}/services/data/{API_VERSION}/ssot/data-model-objects"
    headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
    try:
        response = requests.post(post_url, headers=headers, data=json.dumps(post_payload), proxies=proxies, verify=VERIFY_SSL, timeout=REQUESTS_TIMEOUT)
        response.raise_for_status()
        new_dmo_name = post_payload.get('name')
        print(f"{get_timestamp()}    - ‚úÖ POST DMO bem-sucedido! DMO '{new_dmo_name}' criado.")
        return new_dmo_name, True
    except requests.exceptions.HTTPError as e:
        dmo_name = post_payload.get('name')
        print(f"{get_timestamp()}    - ‚ùå ERRO no POST DMO para '{dmo_name}': {e.response.status_code} - {e.response.text}")
        return dmo_name, False

def get_dmo_mappings(access_token, instance_url, original_dmo_name):
    print(f"{get_timestamp()}    - Buscando mapeamentos para o DMO original: {original_dmo_name}")
    get_url = f"{instance_url}/services/data/{API_VERSION}/ssot/data-model-object-mappings?dataspace=default&dmoDeveloperName={original_dmo_name}"
    headers = {"Authorization": f"Bearer {access_token}"}
    try:
        response = requests.get(get_url, headers=headers, proxies=proxies, verify=VERIFY_SSL, timeout=REQUESTS_TIMEOUT)
        response.raise_for_status()
        data = response.json()
        if data.get("objectSourceTargetMaps"):
            print(f"{get_timestamp()}    - {len(data['objectSourceTargetMaps'])} defini√ß√µes de mapeamento encontradas.")
            return data["objectSourceTargetMaps"]
        else:
            print(f"{get_timestamp()}    - Nenhum mapeamento encontrado para {original_dmo_name}.")
            return []
    except requests.exceptions.HTTPError as e:
        print(f"{get_timestamp()}    - ‚ùå ERRO no GET Mappings para {original_dmo_name}: {e.response.status_code} - {e.response.text}")
        return None

def create_new_mappings(access_token, instance_url, original_mappings, new_dmo_name):
    if not original_mappings: return True

    consolidated_mappings = {}
    for mapping in original_mappings:
        dlo_name = mapping.get("sourceEntityDeveloperName")
        if not dlo_name: continue
        fields = mapping.get("fieldMappings", [])
        if dlo_name not in consolidated_mappings:
            consolidated_mappings[dlo_name] = []
        consolidated_mappings[dlo_name].extend(fields)
    
    print(f"{get_timestamp()}    - {len(consolidated_mappings)} DLO(s) de origem √∫nicos para mapear.")

    post_url = f"{instance_url}/services/data/{API_VERSION}/ssot/data-model-object-mappings?dataspace={NEW_DATA_SPACE_NAME}"
    headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
    all_successful = True

    for dlo_name, all_fields in consolidated_mappings.items():
        
        # --- IN√çCIO DA SE√á√ÉO DE DEPURA√á√ÉO ---
        print("\n" + "-"*20 + f" DEPURA√á√ÉO PARA DLO: {dlo_name} " + "-"*20)
        print(f"{get_timestamp()}    - CAMPOS CONSOLIDADOS (ANTES DO FILTRO):")
        print(json.dumps(all_fields, indent=2))
        # --- FIM DA SE√á√ÉO DE DEPURA√á√ÉO ---

        filtered_fields = [
            {"sourceFieldDeveloperName": f["sourceFieldDeveloperName"], "targetFieldDeveloperName": f["targetFieldDeveloperName"]}
            for f in all_fields
            if f.get("sourceFieldDeveloperName") 
               and f["sourceFieldDeveloperName"] not in SYSTEM_FIELDS_TO_EXCLUDE
        ]
        
        # --- IN√çCIO DA SE√á√ÉO DE DEPURA√á√ÉO ---
        print(f"{get_timestamp()}    - CAMPOS AP√ìS FILTRO (SYSTEM FIELDS):")
        print(json.dumps(filtered_fields, indent=2))
        # --- FIM DA SE√á√ÉO DE DEPURA√á√ÉO ---

        unique_filtered_fields = [dict(t) for t in {tuple(d.items()) for d in filtered_fields}]
        
        post_payload = {"sourceEntityDeveloperName": dlo_name, "targetEntityDeveloperName": f"{new_dmo_name}__dlm", "fieldMapping": unique_filtered_fields}
        
        try:
            response = requests.post(post_url, headers=headers, data=json.dumps(post_payload), proxies=proxies, verify=VERIFY_SSL, timeout=REQUESTS_TIMEOUT)
            response.raise_for_status()
            print(f"{get_timestamp()}    - ‚úÖ POST Mapping bem-sucedido para DLO: {dlo_name}")
        except requests.exceptions.HTTPError as e:
            print(f"{get_timestamp()}    - ‚ùå ERRO no POST Mapping para DLO '{dlo_name}': {e.response.status_code} - {e.response.text}")
            all_successful = False
            
    return all_successful

# --- 5. Orquestra√ß√£o Principal ---
def main():
    # ... (O restante do c√≥digo permanece o mesmo) ...
    print("\n" + "="*50)
    print(f"{get_timestamp()} üöÄ Iniciando script...")
    print(f"    - Modo Clonar DMO: {'ATIVADO' if RUN_CLONE_DMO else 'DESATIVADO'}")
    print(f"    - Modo Criar Mapeamento: {'ATIVADO' if RUN_CREATE_MAPPING else 'DESATIVADO'}")
    print("="*50)

    if not RUN_CLONE_DMO and not RUN_CREATE_MAPPING:
        print(f"{get_timestamp()} ‚ö†Ô∏è  Nenhum modo de opera√ß√£o foi ativado. Verifique as vari√°veis RUN_CLONE_DMO e RUN_CREATE_MAPPING no arquivo .env. Encerrando.")
        return

    access_token, instance_url = authenticate_jwt(SF_LOGIN_URL, SF_CLIENT_ID, SF_USERNAME, SF_PRIVATE_KEY_FILE)
    if not all([access_token, instance_url]):
        print(f"{get_timestamp()} üö´  A execu√ß√£o n√£o pode continuar devido √† falha na autentica√ß√£o.")
        return

    try:
        dmo_df = pd.read_csv(INPUT_CSV_FILE)
        if "DmoDeveloperName" not in dmo_df.columns:
            print(f"{get_timestamp()} ‚ùå ERRO: O arquivo '{INPUT_CSV_FILE}' deve conter uma coluna chamada 'DmoDeveloperName'.")
            return
        dmo_list = dmo_df["DmoDeveloperName"].dropna().unique().tolist()
        print(f"\n{get_timestamp()} üìÑ Arquivo '{INPUT_CSV_FILE}' carregado. {len(dmo_list)} DMOs √∫nicos para processar.")
    except FileNotFoundError:
        print(f"{get_timestamp()} ‚ùå ERRO: Arquivo '{INPUT_CSV_FILE}' n√£o encontrado.")
        return

    success_count = 0
    failure_count = 0
    
    for original_dmo_name in tqdm(dmo_list, desc=f"{get_timestamp()} Processando DMOs"):
        print(f"\n{get_timestamp()} üîÑ Iniciando processamento para: {original_dmo_name}")
        
        dmo_succeeded = False
        mapping_succeeded = False
        new_dmo_name = None
        
        if RUN_CLONE_DMO:
            dmo_definition = get_dmo_definition(access_token, instance_url, original_dmo_name)
            if dmo_definition:
                new_dmo_name, created = create_new_dmo(access_token, instance_url, dmo_definition)
                dmo_succeeded = created
            else:
                dmo_succeeded = False
        else:
            dmo_succeeded = True
            base_api_name = original_dmo_name.replace('__dlm', '')
            new_dmo_name = f"{NEW_DMO_PREFIX}{base_api_name}"
            print(f"{get_timestamp()}    - ‚è© Clonagem de DMO pulada. Usando nome de DMO de destino: {new_dmo_name}")

        if dmo_succeeded and RUN_CREATE_MAPPING:
            original_mappings = get_dmo_mappings(access_token, instance_url, original_dmo_name)
            if original_mappings is not None:
                mapping_succeeded = create_new_mappings(access_token, instance_url, original_mappings, new_dmo_name)
            else:
                mapping_succeeded = False
        elif not RUN_CREATE_MAPPING:
            mapping_succeeded = True

        process_ok = (not RUN_CLONE_DMO or dmo_succeeded) and \
                     (not RUN_CREATE_MAPPING or mapping_succeeded)

        if process_ok:
            success_count += 1
        else:
            failure_count += 1

    print("\n" + "="*50)
    print(f"{get_timestamp()} üéâ Processo conclu√≠do!")
    print(f"  - Total de DMOs na lista: {len(dmo_list)}")
    print(f"  - ‚úÖ Processos conclu√≠dos com sucesso: {success_count}")
    print(f"  - ‚ùå Processos com falha: {failure_count}")
    print("="*50)

if __name__ == "__main__":
    main()